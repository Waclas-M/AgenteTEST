{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b7d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ard.knowledge_graph import KnowledgeGraph\n",
    "from ard.data import DatasetItem\n",
    "\n",
    "# Initialize a knowledge graph\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "# Add data and build relationships\n",
    "# ... (see examples/ for detailed usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hackathon.autogen import generate_hypothesis\n",
    "\n",
    "# Generate hypotheses using AutoGen agents\n",
    "hypothesis = generate_hypothesis.run(subgraph, output_dir=\"results\")\n",
    "# Access hypothesis properties: hypothesis.title, hypothesis.statement, hypothesis.references, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ard.hypothesis import Hypothesis, HypothesisGeneratorProtocol\n",
    "from ard.subgraph import Subgraph\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "\n",
    "@dataclass\n",
    "class SimpleHypothesisGenerator(HypothesisGeneratorProtocol):\n",
    "    \"\"\"A simple hypothesis generator using a single LLM call.\"\"\"\n",
    "\n",
    "    llm: Any  # Your LLM client\n",
    "\n",
    "    def run(self, subgraph: Subgraph) -> Hypothesis:\n",
    "        # Convert subgraph to string representation for the LLM\n",
    "        \n",
    "        graph_text = subgraph.to_cypher_string()\n",
    "\n",
    "        # Create a prompt for the LLM\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following knowledge graph:\n",
    "\n",
    "        {graph_text}\n",
    "\n",
    "        Generate a scientific hypothesis that explains the relationship between\n",
    "        {subgraph.start_node} and {subgraph.end_node}.\n",
    "\n",
    "        Provide your response in this format:\n",
    "        TITLE: [concise title for the hypothesis]\n",
    "        HYPOTHESIS: [detailed hypothesis statement]\n",
    "        REFERENCES: [list of references that support this hypothesis]\n",
    "        \"\"\"\n",
    "\n",
    "        # Get response from LLM\n",
    "        response = self.llm(prompt)\n",
    "\n",
    "        # Parse response\n",
    "        title_line = response.split(\"TITLE:\")[1].split(\"HYPOTHESIS:\")[0].strip()\n",
    "        hypothesis_statement = response.split(\"HYPOTHESIS:\")[1].split(\"REFERENCES:\")[0].strip()\n",
    "\n",
    "        # Parse references (if provided)\n",
    "        references = []\n",
    "        if \"REFERENCES:\" in response:\n",
    "            references_text = response.split(\"REFERENCES:\")[1].strip()\n",
    "            # Simple parsing - split by newlines and filter empty lines\n",
    "            references = [ref.strip() for ref in references_text.split(\"\\n\") if ref.strip()]\n",
    "\n",
    "        # Create and return Hypothesis object\n",
    "        return Hypothesis(\n",
    "            title=title_line,\n",
    "            statement=hypothesis_statement,\n",
    "            source=subgraph,\n",
    "            method=self,\n",
    "            references=references,\n",
    "            metadata={\"generator\": \"SimpleHypothesisGenerator\"}\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"SimpleHypothesisGenerator\"\n",
    "\n",
    "    def to_json(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": str(self),\n",
    "            \"type\": \"simple_llm_generator\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886cb9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Title: MDM2 Negatively Regulates TP53 Activity\n",
      "ðŸ§ª Statement: MDM2, an oncoprotein, negatively regulates the tumor suppressor activity of TP53 through a direct protein-protein interaction. This interaction leads to the ubiquitination and subsequent proteasomal degradation of TP53, thereby reducing cellular levels of TP53 and attenuating its downstream effects, such as cell cycle arrest and apoptosis.  This tight regulation of TP53 by MDM2 is crucial for maintaining cellular homeostasis under normal conditions. However, dysregulation of this interaction, for instance through MDM2 overexpression or TP53 mutations that disrupt MDM2 binding, can contribute to tumorigenesis by impairing TP53's ability to suppress uncontrolled cell growth.\n",
      "ðŸ“š References: ['* **Momand, J., Zambetti, G. P., Olson, D. C., George, D., & Levine, A. J. (1992). The mdm-2 oncogene product forms a complex with the p53 protein and inhibits p53-mediated transactivation.** _Cell_, _69_(7), 1237â€“1245.  This seminal paper established the interaction between MDM2 and TP53 and its impact on TP53 function.', '* **Haupt, Y., Maya, R., Kazaz, A., & Oren, M. (1997). Mdm2 promotes the rapid degradation of p53.** _Nature_, _387_(6630), 296â€“299.**  This study demonstrated that MDM2 mediates TP53 degradation.', '* **Kubbutat, M. H., Jones, S. N., & Vousden, K. H. (1997). Regulation of p53 stability by Mdm2.** _Nature_, _387_(6630), 299â€“303.** This study also showed the role of MDM2 in regulating TP53 stability.', '* **Marine, J. C., et al. (2006). Keeping p53 in check: essential and synergistic functions of Mdm2 and Mdm4.** _Cell Death & Differentiation_, _13_(6), 927â€“934.** This review article provides a comprehensive overview of the MDM2-TP53 interaction and its implications for cancer.', '* **Vousden, K. H., & Prives, C. (2009). Blinded by the Light: The Growing Complexity of p53.** _Cell_, _137_(3), 413â€“431.** This review provides further context on the role of p53 in various cellular processes.']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# ðŸ” Ustaw swÃ³j API key do Gemini\n",
    "genai.configure(api_key=\"AIzaSyA3R_31WvpQJLQz_YnjXSyR1Eq2io1Px8Y\")\n",
    "\n",
    "# ðŸŽ¯ Wybierz model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "# ðŸ§  Funkcja wywoÅ‚ujÄ…ca LLM\n",
    "def gemini_llm(prompt: str) -> str:\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# ðŸ§¬ Prosty mock subgraph do testÃ³w\n",
    "@dataclass\n",
    "class Subgraph:\n",
    "    start_node: str\n",
    "    end_node: str\n",
    "    \n",
    "    def to_cypher_string(self) -> str:\n",
    "        return f\"(n1:Gene {{name: '{self.start_node}'}})-[:INTERACTS_WITH]->(n2:Protein {{name: '{self.end_node}'}})\"\n",
    "\n",
    "# ðŸ”§ UtwÃ³rz subgraph i generator\n",
    "example_subgraph = Subgraph(start_node=\"TP53\", end_node=\"MDM2\")\n",
    "generator = SimpleHypothesisGenerator(llm=gemini_llm)\n",
    "\n",
    "# ðŸš€ Wygeneruj hipotezÄ™\n",
    "hypothesis = generator.run(example_subgraph)\n",
    "\n",
    "# ðŸ§¾ WyÅ›wietl wynik\n",
    "print(\"ðŸ“Œ Title:\", hypothesis.title)\n",
    "print(\"ðŸ§ª Statement:\", hypothesis.statement)\n",
    "print(\"ðŸ“š References:\", hypothesis.references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset', 'DatasetItem', 'Metadata', 'ResearchPaper', 'Triplets', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'dataset', 'dataset_item', 'metadata', 'research_paper', 'triplets']\n"
     ]
    }
   ],
   "source": [
    "import ard\n",
    "\n",
    "print(dir(ard.data))\n",
    "generator = SimpleHypothesisGenerator(llm=gemini_llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
