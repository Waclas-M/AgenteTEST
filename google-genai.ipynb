{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11357591,"sourceType":"datasetVersion","datasetId":7108009}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install google-generativeai langchain langchain-google-genai langgraph chromadb\n\n!pip install -Uq \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:43:37.846333Z","iopub.execute_input":"2025-04-10T17:43:37.846668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\nfrom langgraph.graph import StateGraph, END\nfrom typing import Dict, TypedDict\nfrom langchain_core.messages import HumanMessage\n\nfrom IPython.display import Markdown, display\n\ngenai.__version__\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:43:52.018842Z","iopub.execute_input":"2025-04-10T17:43:52.019244Z","iopub.status.idle":"2025-04-10T17:43:52.027025Z","shell.execute_reply.started":"2025-04-10T17:43:52.019208Z","shell.execute_reply":"2025-04-10T17:43:52.025681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:43:54.400171Z","iopub.execute_input":"2025-04-10T17:43:54.400539Z","iopub.status.idle":"2025-04-10T17:43:54.613368Z","shell.execute_reply.started":"2025-04-10T17:43:54.400482Z","shell.execute_reply":"2025-04-10T17:43:54.612201Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testy ","metadata":{}},{"cell_type":"code","source":"\n# Inicjalizacja modelu Gemini przez LangChain\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-1.5-flash\",\n    temperature=0.3,\n    google_api_key=GOOGLE_API_KEY\n)\n\n\ndef explain_python_code(python_code: str) -> str:\n    \"\"\"\n    Funkcja przyjmuje kod ≈∫r√≥d≈Çowy w Pythonie i zwraca jego wyja≈õnienie\n    \"\"\"\n    prompt = f\"\"\"Jeste≈õ starszym programistƒÖ. Wyja≈õnij krok po kroku, co robi ten kod w Pythonie:\n        \n    ```python\n    {python_code}\n    Wyja≈õnij dzia≈Çanie ka≈ºdej linijki. \n    \"\"\" \n    \n    response = llm.invoke([HumanMessage(content=prompt)]) \n    return response.content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T06:38:53.372831Z","iopub.execute_input":"2025-04-10T06:38:53.373181Z","iopub.status.idle":"2025-04-10T06:38:53.381911Z","shell.execute_reply.started":"2025-04-10T06:38:53.373155Z","shell.execute_reply":"2025-04-10T06:38:53.380832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nsample_code = \"\"\" prompt = \"Please provide me with 3 newest news From US\" baseline_response = client.models.generate_content( model=\"gemini-1.5-flash-001\", contents=[prompt]) print(baseline_response.text) \"\"\" \n\nexplanation = explain_python_code(sample_code) \nprint(\"\\nüß† Wyja≈õnienie kodu:\\n\") \n\nprint(explanation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T06:39:00.711300Z","iopub.execute_input":"2025-04-10T06:39:00.711708Z","iopub.status.idle":"2025-04-10T06:39:04.863014Z","shell.execute_reply.started":"2025-04-10T06:39:00.711673Z","shell.execute_reply":"2025-04-10T06:39:04.861877Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Klasy definiujƒÖce agent√≥w","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nfrom PIL import Image\nimport chromadb\n\n# Ustawienie klucza API Gemini\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nfor model in genai.list_models():\n    print(f\"Model: {model.name}\")\n    print(f\"Supported methods: {model.supported_generation_methods}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:43:59.199972Z","iopub.execute_input":"2025-04-10T17:43:59.200384Z","iopub.status.idle":"2025-04-10T17:43:59.300822Z","shell.execute_reply.started":"2025-04-10T17:43:59.200350Z","shell.execute_reply":"2025-04-10T17:43:59.299676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inicjalizacja trwa≈Çego katalogu dla ChromaDB\nimport os\n\npersistent_directory = \"/kaggle/working/chromadb_storage\"\nos.makedirs(persistent_directory, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:44:28.876603Z","iopub.execute_input":"2025-04-10T17:44:28.876938Z","iopub.status.idle":"2025-04-10T17:44:28.882108Z","shell.execute_reply.started":"2025-04-10T17:44:28.876913Z","shell.execute_reply":"2025-04-10T17:44:28.880784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai\nfrom PIL import Image\nimport chromadb\n\n# Ustawienie klucza API Gemini\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Funkcja do generowania embeddingu zdjƒôcia\n# Poprawiona funkcja do generowania embeddingu zdjƒôcia\ndef generate_image_embedding(image_path):\n    image = Image.open(image_path)\n    model = genai.GenerativeModel('models/gemini-1.5-flash')\n\n    prompt = \"Generate a descriptive caption for embedding purposes.\"\n    response = model.generate_content([prompt, image])\n    \n    # Wygenerowanie embeddingu na podstawie tekstowego opisu zdjƒôcia\n    embedding_model = genai.GenerativeModel('models/embedding-001')\n    embedding = genai.embed_content(\n        model='models/embedding-001',\n        content=response.text,\n        task_type=\"RETRIEVAL_DOCUMENT\"\n    )\n    return embedding['embedding']\n# Funkcja do automatycznego generowania opisu zdjƒôcia przez Gemini\ndef generate_image_caption(image_path):\n    model = genai.GenerativeModel('models/gemini-1.5-flash')\n    image = Image.open(image_path)\n\n    prompt = \"Provide a concise and accurate description of this image.\"\n    response = model.generate_content([prompt, image])\n\n    return response.text\n\n# Inicjalizacja bazy ChromaDB\nchroma_client = chromadb.PersistentClient(path=persistent_directory)\ncollection = chroma_client.get_or_create_collection(name=\"flag2\")\n\n# Funkcja do dodawania zdjƒôcia do bazy z automatycznym opisem\ndef add_image_to_db(image_path, image_id):\n    embedding = generate_image_embedding(image_path)\n    caption = generate_image_caption(image_path)\n\n    collection.add(\n        embeddings=[embedding],\n        documents=[caption],\n        ids=[image_id],\n        metadatas=[{\"path\": image_path}]\n    )\n\n    print(f\"Image '{image_id}' added to DB with caption: {caption}\")\n\n# Przyk≈Çad u≈ºycia:\nadd_image_to_db(\"/kaggle/input/testgcc/IMG_1495.jpeg\", \"flag_pl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:47:10.413892Z","iopub.execute_input":"2025-04-10T17:47:10.414331Z","iopub.status.idle":"2025-04-10T17:47:13.562429Z","shell.execute_reply.started":"2025-04-10T17:47:10.414296Z","shell.execute_reply":"2025-04-10T17:47:13.561211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Funkcja do embeddingu zapytania tekstowego\ndef generate_query_embedding(query):\n    embedding = genai.embed_content(\n        model=\"models/embedding-001\",\n        content=query,\n        task_type=\"RETRIEVAL_QUERY\"\n    )\n    return embedding[\"embedding\"]\n\n# Agent wyszukujƒÖcy najbli≈ºszy obraz na podstawie prompta\ndef find_image_by_prompt(prompt, collection, top_k=1):\n    query_embedding = generate_query_embedding(prompt)\n    \n    # Wyszukiwanie w bazie\n    results = collection.query(\n        query_embeddings=[query_embedding],\n        n_results=top_k\n    )\n\n    if not results['ids'][0]:\n        print(\"Brak wynik√≥w.\")\n        return\n\n    image_path = results['metadatas'][0][0]['path']\n    caption = results['documents'][0][0]\n    print(f\"Najlepiej pasujƒÖcy opis: {caption}\")\n\n    # Wy≈õwietlanie obrazu\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(caption)\n    plt.show()\n\n# Przyk≈Çad u≈ºycia:\nfind_image_by_prompt(\"flaga polski\", collection)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:49:59.162709Z","iopub.execute_input":"2025-04-10T17:49:59.163105Z","iopub.status.idle":"2025-04-10T17:49:59.666245Z","shell.execute_reply.started":"2025-04-10T17:49:59.163060Z","shell.execute_reply":"2025-04-10T17:49:59.664626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Code Explainer ","metadata":{}},{"cell_type":"code","source":"# Create the CodeExplainer agent\nexplainer_agent = CodeExplainer(name=\"CodeExplainer\", model=\"gemini-1.5-flash\", temperature=0.2)\n\n# We will now use the LLM as a \"judge\" to evaluate correctness or validity of the code\n\njudge_prompt = f\"\"\"\nYou are a strict yet fair code judge. Evaluate the correctness of the agent's response in the context of the provided code snippet.\n\nConsider the following criteria:\n1. Logic and correctness: Is the solution logically sound and functionally correct?\n2. Best practices: Does the agent adhere to good coding conventions and best practices?\n3. Clarity: Is the explanation well-structured, understandable, and adequately justified?\n\nProvide:\n- A single overall score from 1 to 5 (1 = very poor, 5 = excellent).\n- A concise explanation (1‚Äì2 sentences) summarizing the main reasons for your rating.\n\nCode:\n{sample_code}\n\nAgent Response:\n{explanation}\n\"\"\"\n\n # We directly call the LLM client on our judge prompt \njudgement_response = explainer_agent.llm.invoke([HumanMessage(content=judge_prompt)]) \nprint(\"\\n=== LLM AS JUDGE ===\\n\") \nprint(judgement_response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T19:25:53.389346Z","iopub.execute_input":"2025-04-08T19:25:53.389786Z","iopub.status.idle":"2025-04-08T19:25:54.006252Z","shell.execute_reply.started":"2025-04-08T19:25:53.389751Z","shell.execute_reply":"2025-04-08T19:25:54.005141Z"}},"outputs":[],"execution_count":null}]}